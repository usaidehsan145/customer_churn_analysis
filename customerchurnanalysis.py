# -*- coding: utf-8 -*-
"""CustomerChurnAnalysis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cKsKx5bd4mBIU4kLiJWm8AXJHOPmj-JY
"""

import numpy as np
import pandas as pd
from google.colab import files
import os
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

data = files.upload()

df = pd.read_excel("E Commerce Dataset.xlsx")

df.head()

df.nunique()

# Get unique values for each column
for column in df.columns:
    unique_values = df[column].unique()
    print(f"Unique values in {column}: {unique_values}")

gender_mapping = {'Female': 0, 'Male': 1}
df['Gender'] = df['Gender'].map(gender_mapping)

device_mapping = {'Computer': 0, 'Mobile Phone': 1, 'Phone': 1}
df['PreferredLoginDevice'] = df['PreferredLoginDevice'].map(device_mapping)

df['PreferredPaymentMode'] = df['PreferredPaymentMode'].replace({'CC': 'Credit Card', 'COD': 'Cash on Delivery'})

# Display the frequency of occurrence of each payment type
payment_frequency = df['PreferredPaymentMode'].value_counts()

# Display the result
print("Frequency of occurrence of each payment type:")
print(payment_frequency)

df = pd.get_dummies(df, columns = ['PreferredPaymentMode'],prefix = ' Mode')

# Display the frequency of occurrence of each payment type
order_cat_mapping = {
    'Mobile Phone': 'Mobile'
}

df['PreferedOrderCat'] = df['PreferedOrderCat'].replace(order_cat_mapping)

ordered_frequency = df['PreferedOrderCat'].value_counts()

# Display the result
print("Frequency of occurrence of each ordered type:")
print(ordered_frequency)

# merge others with grocery to avoid maximum biasness in dataset
df['PreferedOrderCat'] = df['PreferedOrderCat'].replace({'Grocery': 'Others'})

# one hot encoding
df = pd.get_dummies(df, columns = ['PreferedOrderCat'],prefix = ' Cat')

# label encoding the maritalStatus

maritalStatus_mapping = {'Single': 0, 'Divorced': 1, 'Married': 2}
df['MaritalStatus'] = df['MaritalStatus'].map(maritalStatus_mapping)

df.head()

correlation_matrix_all = df.corr()
print("Correlation Matrix with All Features:")
print(correlation_matrix_all['Churn'].sort_values(ascending=False))

correlation_matrix = df.corr()

# Set up the matplotlib figure
plt.figure(figsize=(15, 12))

# Generate a mask for the upper triangle
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# Draw the heatmap with the mask and correct aspect ratio
sns.heatmap(correlation_matrix, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,
            square=True, linewidths=.5, cbar_kws={"shrink": 0.8})

plt.title('Correlation Matrix')
plt.show()

df = df.dropna()

# Check for null values in the cleaned DataFrame
null_values = df.isnull().sum()

# Display columns with null values (if any)
columns_with_null = null_values[null_values > 0].index

if len(columns_with_null) == 0:
    print("No remaining null values in the cleaned dataset.")
else:
    print("Columns with remaining null values:")
    print(columns_with_null)
    print("\nNumber of null values in each column:")
    print(null_values[columns_with_null])

# Separate features and target variable
X = df.drop('Churn', axis=1)  # Features
y = df['Churn']  # Target variable

# Standardize the features (important for PCA)
scaler = StandardScaler()
X_standardized = scaler.fit_transform(X)

# Apply PCA
pca = PCA()
X_pca = pca.fit_transform(X_standardized)

# Explained variance ratio
explained_variance_ratio = pca.explained_variance_ratio_

# Plot the explained variance ratio
plt.figure(figsize=(10, 6))
plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), marker='o', linestyle='--')
plt.title('Explained Variance Ratio vs. Number of Principal Components')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.grid(True)
plt.show()

plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), marker='o', linestyle='--')
plt.xlabel('Number of Principal Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.title('Cumulative Explained Variance')
plt.show()